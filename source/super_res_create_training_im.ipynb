{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#import\n",
    "import javabridge\n",
    "import bioformats\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import scipy\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import filters\n",
    "from skimage import exposure\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import register_translation\n",
    "\n",
    "javabridge.start_vm(class_path=bioformats.JARS)\n",
    "\n",
    "import tifffile\n",
    "from skimage.transform import resize\n",
    "from tifffile import imsave\n",
    "from PIL import Image\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "from torchvision.models import vgg16_bn\n",
    "from  functions_super_res_create_training_im import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths were the different images can be found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '../../../../../SCRATCH2/marvande/data/train/'\n",
    "\n",
    "#path of big LR:\n",
    "path_lr_whole = path + 'LR/0013_Scan1.qptiff'\n",
    "\n",
    "#path where we will save the resized HR phenotype patches:\n",
    "path_lr = path + 'HR/HR_patches_resized/tiff_files/'\n",
    "\n",
    "#path to HR phenotype patches:\n",
    "path_hr = path + 'HR/HR_patches_original/'\n",
    "\n",
    "#path where we will save the HR patches in 6 channel form\n",
    "#(originally 6 phenotype images with 3 channels)\n",
    "path_save_hr = path + 'HR/HR_patches_train/tiff_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data: \n",
    "Take a look at a few images and their shapes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load an HR patch and a LR scan to have a look at it:\n",
    "whole_lr_scan = bioformats.load_image(path_lr_whole)\n",
    "\n",
    "hr_patch = bioformats.load_image(path_hr + 'im3/0013_[39667,16250].im3')\n",
    "\n",
    "hr_patho_patch = bioformats.load_image(\n",
    "    path_hr + '0124_[43058,10798]_CK_OPAL690_path_view.tif')\n",
    "\n",
    "print('Whole LR scan shape:' + str(whole_lr_scan.shape))\n",
    "print('HR patch shape:' + str(hr_patch.shape))\n",
    "print('HR patho patch shape:' + str(hr_patho_patch.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize one phenotype patch to have a look at them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to import again because somehow bugs:\n",
    "from skimage.transform import resize\n",
    "\n",
    "#Resize HR patch to LR patch size of (500, 669):\n",
    "hr_patch = bioformats.load_image(\n",
    "    path_hr + '0124_[43058,10798]_CK_OPAL690_path_view.tif')\n",
    "\n",
    "#Take one channel:\n",
    "print('One channel of HR patho patch:')\n",
    "print('HR patch shape:' + str(hr_patch.shape))\n",
    "plt.imshow(hr_patch[:, :, 1])\n",
    "plt.show()\n",
    "\n",
    "print('')\n",
    "hr_patch_resized = resize(hr_patch, (500, 669), anti_aliasing=True)\n",
    "print('Resized HR patch shape:' + str(hr_patch_resized.shape))\n",
    "plt.imshow(hr_patch_resized[:, :, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No visible difference. Looks good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our training data: \n",
    "We will resize the HR phenotype patches (6 phenotypes with 3 channels) to images of 6 channels (one per phenotype). We will create two training dataset for our model: \n",
    "- resized patches (LR) of size (500, 669, 6)\n",
    "- original patches (HR) of size (500, 669, 6)\n",
    "\n",
    "We wrote some functions for that (see `functions_super_res_create_training_im.py`) and will test them first to see if they behave properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `correct_file()`: \n",
    "a function that tests whether a file has the location, patient and phenotype we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if you want to see the signature:\n",
    "#?correct_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = ['CD4', 'CK', 'DAPI', 'CD3', 'FoxP3', 'CD8']\n",
    "patient = '0013'\n",
    "location = '[39667,16250]'\n",
    "\n",
    "# Some checks for our function:\n",
    "assert (correct_file(\n",
    "    location, patient, phenotypes,\n",
    "    '0013_[39667,16250]_Autofluorescence_path_view.tif') == False)\n",
    "assert (correct_file(location, patient, phenotypes,\n",
    "                     '0013_[39667,16250]_CD4_Rhod_path_view.tif') == True)\n",
    "assert (correct_file(location, patient, phenotypes,\n",
    "                     '0015_[39667,16250]_CD4_Rhod_path_view.tif') == False)\n",
    "assert (correct_file(location, patient, phenotypes,\n",
    "                     '0013_[39660,16253]_CD4_Rhod_path_view.tif') == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test `multichannel_phenotype()`: \n",
    "a function that creates a 6 channel image for a location of an HR patch\n",
    "    each channel is a phenotype output of inform. We plot an image with all its six channels to have a look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if you want to see the signature:\n",
    "#?multichannel_phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test our functions:\n",
    "patient = '0124'\n",
    "location = '[43058,10798]'\n",
    "phenotypes = ['CD4', 'CK', 'DAPI', 'CD3', 'FoxP3', 'CD8']\n",
    "new_size = (500, 669, 3)\n",
    "\n",
    "#create the image\n",
    "arr = multichannel_phenotype(patient=patient,\n",
    "                             location=location,\n",
    "                             phenotypes=phenotypes,\n",
    "                             path_hr=path_hr,\n",
    "                             path_lr=path_lr,\n",
    "                             new_size=new_size)\n",
    "#plot the channels:\n",
    "show_6_chann_phen(arr, phenotypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention: somehow bioformats is unable to read all 6 channels, use tifffile.imread (see above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the LR and HR training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LR train data: \n",
    "with os.scandir(path_hr) as entries:\n",
    "        files = [entry.name for entry in entries if entry.is_file()]\n",
    "\n",
    "patients = np.unique([file[0:4] for file in files])\n",
    "print('Patients:', patients)\n",
    "\n",
    "phenotypes = ['CD4', 'CK', 'DAPI', 'CD3', 'FoxP3', 'CD8']\n",
    "new_size = (500, 669, 3)\n",
    "\n",
    "create_train_data(patients, phenotypes, path_hr = path_hr, path_lr = path_lr, resize_size = new_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HR train data:\n",
    "\n",
    "patients = np.unique([file[0:4] for file in files])\n",
    "print('Patients:', patients)\n",
    "\n",
    "phenotypes = ['CD4', 'CK', 'DAPI', 'CD3', 'FoxP3', 'CD8']\n",
    "\n",
    "create_train_data(patients=patients,\n",
    "                  phenotypes=phenotypes,\n",
    "                  path_hr=path_hr,\n",
    "                  path_lr=path_save_hr,\n",
    "                  to_resize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
